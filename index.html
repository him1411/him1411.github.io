<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Himanshu Gupta</title>

  <meta name="author" content="Himanshu Gupta">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Himanshu Gupta</name>
                  </p>
                  <p>
                    I am an Applied Scientist at Stores Foundation AI (San Francisco Bay Area), where I work on mid-training, post-training optimization, synthetic data creation and evaluation of large foundation models. 
                    I developed robust FLOP-efficient methods for mid-training <strong>800B ultra-sparse Mixture-of-Experts (MoE)</strong> models, significantly elevating performance in reasoning, math, and coding. 
                    I have hands on experience with <a href="https://github.com/NVIDIA/Megatron-LM">Megatron-LM</a>, <a href="https://github.com/volcengine/verl">verl</a> (SFT, DPO, GRPO), <a href="https://github.com/vllm-project/vllm">vLLM </a>,  <a href="https://github.com/sgl-project/sglang">SGLang </a> and <a href="https://github.com/huggingface/trl">TRL </a>.
                    I also had the opportunity to develop multi-lingual 7B foundation model from scratch at <a href="https://olakrutrim.com/">Krutrim</a> which focused on 10 Indic languages (<a href="https://www.youtube.com/watch?v=5BhN0Qopt_0&t=2203s">Media Coverage</a> , <a href="https://arxiv.org/abs/2502.09642">Technical Report</a>). 
                    My thesis was on <a href="https://www.proquest.com/openview/fed10c620f17cfa986f7c266e97158b8/1?pq-origsite=gscholar&cbl=18750&diss=y">Sample efficiency of Instruction Tuned Models</a> under the guidance of Dr. <a href="https://swarooprm.github.io">Swaroop Mishra</a> and Prof. <a href="https://www.public.asu.edu/~cbaral/">Chitta Baral</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:him141195@gmail.com">Email</a> ¬†/¬†
                    <a href="https://drive.google.com/file/d/19QokRjFh1JwS0em_fXmaDFUDynrI7DdD/view?usp=sharing">CV</a> ¬†/¬†
                    <a href="https://scholar.google.com/citations?user=ydjuhxsAAAAJ&hl=en">Google Scholar</a> ¬†/¬†
                    <a href="https://twitter.com/himanshu_gup14">X</a> ¬†/¬†
                    <a href="https://www.linkedin.com/in/himanshugupta14/">Linkedin</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile_pic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile_pic.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading id="research">
                    Research
                  </heading>
                  <p>
                    My main research contributions are showcasing various aspects of Instruction Tuning (
<a href="https://arxiv.org/abs/2306.05539">Sample Efficiency</a>, 
<a href="https://aclanthology.org/2024.naacl-short.63/">Aspect Based Sentiment Analysis</a>,
<a href="https://arxiv.org/abs/2311.09564">Long Sequence Medical Tasks</a>, 
<a href="https://arxiv.org/abs/2109.08079">Financial NER</a>, 
<a href="https://ieeexplore.ieee.org/abstract/document/10646727/">Variable Name Recovery with Decompiled Output</a>, 
<a href="https://aclanthology.org/2024.starsem-1.35/">Event Detection</a>
), 
Mathematical Benchmarking (
<a href="https://aclanthology.org/2023.eacl-main.30/">Numerical Feasibility</a>, 
<a href="https://arxiv.org/abs/2406.15444">Adversarial Math Word Problems</a>, 
<a href="https://arxiv.org/abs/2410.14702">Multimodal Mathematical Benchmarking</a>,
<a href="https://arxiv.org/abs/2501.14249">Humanity's Last Exam</a>
),
<a href="https://arxiv.org/abs/2310.17876">Synthetic Data Generation</a> and 
<a href="https://openreview.net/forum?id=jAel595Egi">Efficient LLMs-as-a-Judge</a>.
                    My recent research focuses on building large foundation models that excel at instruction following, adherence to detailed guidelines, and high-precision reasoning, with particular emphasis on enhancing mid-training corpora and RL-based post-training alignment.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          

          
          <!-- <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:-10px">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;vertical-align:middle;width:63%">
                  <heading id="news">
                    News
                  </heading>
                  <p>
                  <div style="width:100%;overflow-y:scroll; height:100px;">
                    <ul id="News">
                      <p>
                      </p>
                      <li> <span> <b>10.2025</b> 2 Papers accepted in NeurIPS 2025 Workshops
                      <li> <span> <b>09.2025</b> Serving as Reviewer for ICLR 2026
                      <li> <span> <b>06.2025</b> Serving as Reviewer for COLM 2025
                      <li> <span> <b>02.2025</b> Contributed to <a href="https://arxiv.org/pdf/2501.14249">HLE</a> which is available now!
                      <li> <span> <b>02.2025</b> Serving as Reviewer for ICLR 2025
                      <li> <span> <b>12.2024</b> Served as Reviewer for ACL ARR (April, June, August, October, December) 2024
                      <li> <span> <b>11.2024</b> Reached 200 citations
                      <li> <span> <b>07.2024</b> <a href="https://arxiv.org/abs/2310.17876">TarGEN</a> accepted at COLM2024
                      <li> <span> <b>05.2024</b> <a href="https://arxiv.org/abs/2305.16357">EDM 3</a> accepted at SEM NAACL 2024
                      <li> <span> <b>03.2024</b> <a href="https://arxiv.org/abs/2302.08624">InstructABSA</a> accepted at NAACL 2024
                      <li> <span> <b>01.2024</b> Reached 100 citations
                      <li> <span> <b>12.2023</b> Joined Amazon as an Applied Scientist
                      <li> <span> <b>12.2023</b> Graduated from Arizona State University with Distinction
                      <li> <span> <b>08.2023</b> Received 1500$ merit scholarship from School of Computing and AI at ASU
                      <li> <span> <b>07.2023</b> Started 40hr co-op as Applied Scientist at <a href="https://olakrutrim.com/">Krutrim</a>
                      <li> <span> <b>06.2023</b> <a href="https://arxiv.org/abs/2305.05079">Paper</a> accepted at ACL 2023
                      <li> <span> <b>05.2023</b> Started internship at Amazon Alexa
                      <li> <span> <b>01.2022</b> Started Masters in Computer Science at Arizona State University
                      <li> <span> <b>07.2019</b> Joined American Express AI Labs as a Research Engineer
                      <li> <span> <b>06.2019</b> Graduated from BITS Pilani
                      </li>
                    </ul>
                  </div>
                  </p>
                </td>
              </tr>
            </tbody>
          </table> -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Papers</heading>
                </td>
              </tr>


                <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2509.13332">
                      <papertitle>Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness</papertitle>
                    </a>
                  </span>
                  <br>Pratik Jayarao, <strong>Himanshu Gupta</strong>, Neeraj Varshney, Chaitanya Dwivedi<br>
                  <strong>NeurIPS 2025 Workshop on Efficient Reasoning</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>


              <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2410.14702">
                      <papertitle>PolyMATH: A Challenging Multi-modal Mathematical Reasoning Benchmark</papertitle>
                    </a>
                  </span>
                  <br>
                  <strong>Himanshu Gupta</strong>, Shreyas Verma, Ujjwala Anantheswaran, Kevin Scaria, Mihir Parmar,
                  Swaroop Mishra, Chitta Baral<br>
                  <strong>NeurIPS FoRML Workshop 2025</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              
              <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2502.09642">
                      <papertitle>Krutrim LLM: Multilingual Foundational Model for over a Billion People</papertitle>
                    </a>
                  </span>
                  <br>
                  Aditya Kallappa....Arveti Manjunath, <strong>Himanshu Gupta</strong>... Chandra Khatri<br>
                  <strong>preprint</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>


              <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2501.14249">
                      <papertitle>Humanity's Last Exam</papertitle>
                    </a>
                  </span>
                  <br>
                  Scale AI team, ....Chris Harjadi, <strong>Himanshu Gupta</strong>, Stephen Malina....<br>
                  <strong>preprint</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              

              <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2406.15444">
                      <papertitle>Investigating the Robustness of LLMs on Math Word Problems</papertitle>
                    </a>
                  </span>
                  <br>
                  Ujjwala Anantheswaran, <strong>Himanshu Gupta</strong>, Kevin Scaria, Shreyas Verma, Chitta Baral,
                  Swaroop Mishra<br>
                  <strong>Reasoning and Planning for LLMs @ ICLR 2025</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2310.17876">
                      <papertitle>TarGEN: Targeted Data Generation with Large Language Models</papertitle>
                    </a> </span>
                  <br>
                  <strong>Himanshu Gupta</strong>, Kevin Scaria, Ujjwala Anantheswaran, Shreyas Verma, Mihir Parmar,
                  Saurabh Arjun Sawant, Chitta Baral, Swaroop Mishra<br>
                  <strong>COLM 2024</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2305.16357">
                      <papertitle>EDM3: Event Detection as Multi-task Text Generation</papertitle>
                    </a> </span>
                  <br>
                  Ujjwala Anantheswaran, <strong>Himanshu Gupta</strong>, Mihir Parmar, Kuntal Kumar Pal, Chitta Baral
                  <br>
                  <strong>SEM NAACL 2024</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2302.08624">
                      <papertitle>InstructABSA: Instruction Learning for Aspect Based Sentiment
                        Analysis</papertitle>
                    </a> </span>
                  <br>
                  Kevin Scaria, <strong>Himanshu Gupta</strong>, Siddharth Goyal, Saurabh Arjun Sawant, Swaroop Mishra,
                  Chitta Baral <br>
                  <strong>NAACL 2024</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>
              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://www.atipriya.com/files/papers/varbert_oakland24.pdf">
                      <papertitle>‚ÄúLen or index or count, anything but v1‚Äù: Predicting Variable Names in Decompilation
                        Output with Transfer Learning</papertitle>
                    </a>
                  </span>
                  <br>
                  Kuntal Kumar Pal, Ati Priya Bajaj, Pratyay Banerjee, Audrey Dutcher, Mutsumi Nakamura, Zion
                  Leonahenahe Basque, <strong>Himanshu Gupta</strong>, Saurabh Arjun Sawant, Ujjwala Anantheswaran, Yan
                  Shoshitaishvili, Adam Doup√©, Chitta Baral, Ruoyu Wang <br>
                  <strong>IEEE S&P 2023</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span>
                    <a href="https://arxiv.org/abs/2305.05079">
                      <papertitle>A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an
                        Instantiation in Authorship Attribution</papertitle>
                    </a>
                  </span>
                  <br>
                  Neeraj Varshney, <strong>Himanshu Gupta</strong>, Eric Robertson, Bing Liu, Chitta Baral <br>
                  <strong>ACL 2023</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2210.07471">
                      <papertitle>"John is 50 years old, can his son be 65?" Evaluating NLP Models' Understanding of
                        Feasibility</papertitle>
                    </a> </span>
                  <br>
                  <strong>Himanshu Gupta</strong>, Neeraj Varshney, Swaroop Mishra, Kuntal Kumar Pal, Saurabh Arjun
                  Sawant, Kevin Scaria, Siddharth Goyal, Chitta Baral <br>
                  <strong>EACL 2023</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2109.08079">
                      <papertitle>Context-NER : Contextual Phrase Generation at Scale</papertitle>
                    </a> </span>
                  <br>
                  <strong>Himanshu Gupta</strong>, Shreyas Verma, Santosh Mashetty, Swaroop Mishra <br>
                  <strong>NeurIPS ENLSP Workshop 2022</strong><br>
                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2311.09564">
                      <papertitle>LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks</papertitle>
                    </a>
                  </span>
                  <br>
                  Mihir Parmar, Aakanksha Naik, <strong>Himanshu Gupta</strong>, Disha Agrawal, Chitta Baral <br>
                  <strong>preprint</strong><br>
                </td>
              </tr>

                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>
              <tr>

                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  <span> <a href="https://arxiv.org/abs/2306.05539">
                      <papertitle>Instruction Tuned Models are Quick Learners</papertitle>
                    </a> </span>
                  <br>
                  <strong>Himanshu Gupta</strong>, Saurabh Arjun Sawant, Swaroop Mishra, Mutsumi Nakamura, Arindam Mitra,
                  Santosh Mashetty, Chitta Baral <br>
                  <strong>preprint</strong><br>


                </td>
              </tr>
                <tr><td colspan="2" style="padding-left: 20px;">¬†</td></tr>

              <tr>
                <td width="75%" valign="middle" colspan="2" style="padding-left: 20px;">
                  Please check <a
                    href="https://scholar.google.com/citations?hl=en&user=ydjuhxsAAAAJ&view_op=list_works&sortby=pubdate">my
                    google scholar</a> page for all the papers.
                </td>
              </tr>

            </tbody>
          </table>




          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Education</heading>
                          <p>
                          <ul>
                            <li><b>01.2022 - 12.2023</b> Masters (with Thesis) in Computer Science from <a
                                href="https://www.asu.edu/">Arizona State University</a>  </li>
                            <li><b>08.2015 - 07.2019</b> B.E. with Hons. in Electrical and Electronics Engineering, <a
                                href="https://www.bits-pilani.ac.in/">BITS Pilani,India</a> </li>
                          </ul>
                          </p>
                        </td>
                      </tr>
                    </tbody>
                  </table>

                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Experience</heading>
                          <p>
                          <ul>
                            <li><b>12.2023 - present</b> Applied Scientist at Amazon (Stores Foundation AI Team)</li>
                            <li><b>08.2023 - 11.2023</b> Founding Scientist Scientist at <a
                                href="https://olakrutrim.com/">Krutrim</a></li>
                            <li><b>05.2023 - 07.2023</b> Internship at Amazon Alexa</li>
                            <li><b>01.2022 - 05.2023</b> Graduate Research Assistant at CogInt Labs, ASU with <a
                                href="https://www.public.asu.edu/~cbaral/">Dr. Chitta Baral</a></li>
                            <li><b>01.2019 - 12.2021</b> AI Researcher at American Express AI Labs. Supervised by <a
                                href="https://scholar.google.com/citations?user=dZQOltMAAAAJ&hl=en">Dr. Himanshu Shrad
                                Bhatt</a></li>
                            <li><b>01.2018 - 12.2018</b> Research Intern at Covenant University with <a
                                href="https://scholar.google.com/citations?user=AFjvjTgAAAAJ&hl=en">Dr. Sanjay
                                Misra</a></li>
                            <li><b>01.2018 - 12.2018</b> Undergraduate Research Assistant at BITS Pilani with <a
                                href="https://dblp.org/pid/158/5831.html">Dr. NL Bhanu Murthy</a></li>
                          </ul>
                          </p>
                        </td>
                      </tr>

                    </tbody>
                  </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Honors and Awards</heading>
                          <p>
                          <ul>
                            <li><b>2024 - 2025</b> Served as a Reviewer for ICLR (2025, 2026) COLM 2025, NAACL 2024, ACL 2024, ACL ARR (April, June, August, October, December) 2024 and SDU@AAAI 2024. </li>
                            <li><b>2022 - 2023</b> Received Masters Graduate fellowship for Spring, Summer and Fall 2022 at Arizona State University. Also received Engineering Graduate Fellowship award for academic performance in Masters Study. </li>
                            <li><b>2022 - 2023</b> Project mentor and supervisor for 16 Students for CSE 576: Advanced topics in NLP. Responsible for Problem statement delivery, setting up research goals, clearing coding doubts for the project of the students. The Project was 50% of the entire coursework.</li>
                            <li><b>2022 - 2023</b> Involved in writing $6 Million grant to IARPA for Authorship Privacy Research for CogInt Labs.</li>
                            <li><b>2019 - 2021</b> Filed 3 patents in American Express.</li>
                            <li><b>2019</b> Secured World Rank 2 among 6000+ teams in HackHarvard Global 2019 Hackathon on the industry based education track. Was invited to Harvard University to present the project.</li>
                            <li><b>2014</b> Secured a rank of 901 among 1.4 million students PAN India to receive KVPY fellowship</li>
                          </ul>
                          </p>
                        </td>
                      </tr>

                    </tbody>
                  </table>

                  

                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
